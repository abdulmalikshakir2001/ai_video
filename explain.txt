function createAssFile(transcriptionData: any, subtitleStyle: any) {
    const transcription = JSON.parse(transcriptionData);
    let assContent = `
    [Script Info]
    Title: ${'Subtitles'}
    ScriptType: v4.00+
    
    [V4+ Styles]
    Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
    Style: Default,${subtitleStyle.fontFamily},${subtitleStyle.fontSize.replace('px', '')},&H00FFFFFF,&H00000000,&H00000000,&H00000000,1,0,0,2,10,10,${subtitleStyle.bottom.replace('px', '')},0
    
    [Events]
    Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
    `;

    let lastEndTime = 0; // Track the last word's end time to handle missing timestamps

    // Helper function to calculate exact box width based on text length, font size, and small padding
    function calculateBoxWidth(text, fontSize) {
        const charWidth = fontSize * 0.40; // Adjust the scaling factor
        const textWidth = text.length * charWidth;
        
        return textWidth 
    }

    // Helper function to calculate box height based on font size (no extra padding)
    function calculateBoxHeight(fontSize) {
        return fontSize; // Exact height based on font size
    }

    // Iterate through each transcription segment
    transcription.segments.forEach((segment: any) => {
        const words = segment.words;

        // Group words in sets of three
        for (let i = 0; i < words.length; i += 3) {
            const wordGroup = words.slice(i, i + 3);

            // Handle missing start/end times by using the last known end time
            const groupStartTime = wordGroup[0].start ? formatTime(wordGroup[0].start) : formatTime(lastEndTime);
            const groupEndTime = wordGroup[wordGroup.length - 1].end ? formatTime(wordGroup[wordGroup.length - 1].end) : formatTime(lastEndTime + 2); // Default 2-second duration

            // Join the words in the group to form the subtitle text
            const subtitleText = wordGroup.map((word: any) => word.word.toUpperCase()).join(' ');

            // Update the last end time if the current group has valid end time
            if (wordGroup[wordGroup.length - 1].end) {
                lastEndTime = wordGroup[wordGroup.length - 1].end;
            } else {
                lastEndTime += 2; // If no valid end time, increment by 2 seconds
            }

            // Calculate box width and height based on text length and font size
            const fontSize = parseInt(subtitleStyle.fontSize.replace('px', '')); // Get font size as a number
            const boxWidth = calculateBoxWidth(subtitleText, fontSize); // Exact width based on text length + small padding
            const boxHeight = calculateBoxHeight(fontSize); // Exact height based on font size
            const cornerRadius = 10; // Corner radius for rounded corners

            // Create the vector shape with rounded corners and dynamic width matching the text size
            const roundedBox = `{\\1c&H00C1B6FF&\\p1}m ${cornerRadius} 0 l ${boxWidth - cornerRadius} 0 b ${boxWidth} 0 ${boxWidth} 0 ${boxWidth} ${cornerRadius} l ${boxWidth} ${boxHeight - cornerRadius} b ${boxWidth} ${boxHeight} ${boxWidth} ${boxHeight} ${boxWidth - cornerRadius} ${boxHeight} l ${cornerRadius} ${boxHeight} b 0 ${boxHeight} 0 ${boxHeight} 0 ${boxHeight - cornerRadius} l 0 ${cornerRadius} b 0 0 0 0 ${cornerRadius} 0{\\p0}`; // Rounded rectangle
            const subtitleWithFade = `{\\fad(150,150)}${subtitleText}`;

            // Add the background shape (on a lower layer, such as layer 0)
            assContent += `Dialogue: 0,${groupStartTime},${groupEndTime},Default,,0,0,0,,${roundedBox}\n`; // Background on lower layer

            // Add the text (on a higher layer, such as layer 1)
            assContent += `Dialogue: 1,${groupStartTime},${groupEndTime},Default,,0,0,0,,${subtitleWithFade}\n`; // Text on higher layer
        }
    });

    return assContent;
}








function createAssFile(transcriptionData: any, subtitleStyle: any) {
  const transcription = JSON.parse(transcriptionData);
  let assContent = `
  [Script Info]
  Title: ${'Subtitles'}
  ScriptType: v4.00+
  
  [V4+ Styles]
  Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
  Style: Default,${subtitleStyle.fontFamily},${subtitleStyle.fontSize.replace('px', '')},&H00FFFFFF,&H00000000,&H00000000,&H00000000,1,0,0,2,10,10,${subtitleStyle.bottom.replace('px', '')},0
  
  [Events]
  Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
  `;

  let lastEndTime = 0; // Track the last word's end time to handle missing timestamps

  // Iterate through each transcription segment
  transcription.segments.forEach((segment: any) => {
      const words = segment.words;

      // Group words in sets of three
      for (let i = 0; i < words.length; i += 3) {
          const wordGroup = words.slice(i, i + 3);

          // Handle missing start/end times by using the last known end time
          const groupStartTime = wordGroup[0].start ? formatTime(wordGroup[0].start) : formatTime(lastEndTime);
          const groupEndTime = wordGroup[wordGroup.length - 1].end ? formatTime(wordGroup[wordGroup.length - 1].end) : formatTime(lastEndTime + 2); // Default 2-second duration

          // Join the words in the group to form the subtitle text
          const subtitleText = wordGroup.map((word: any) => word.word.toUpperCase()).join(' ');

          // Update the last end time if the current group has valid end time
          if (wordGroup[wordGroup.length - 1].end) {
              lastEndTime = wordGroup[wordGroup.length - 1].end;
          } else {
              lastEndTime += 2; // If no valid end time, increment by 2 seconds
          }

          // Add the text (on a higher layer, such as layer 1)
          const subtitleWithFade = `{\\fad(150,150)}${subtitleText}`;

          // Add the subtitle text
          assContent += `Dialogue: 1,${groupStartTime},${groupEndTime},Default,,0,0,0,,${subtitleWithFade}\n`;
      }
  });

  return assContent;
}








word highlight with =======================>
 const coloredWords = wordGroup.map((w: any, i: number) => {
                  if (i === index) {
                      return `{\\c&H00FFFF00}${w.word.toUpperCase()}`; // Yellow for the current word
                  } else {
                      return `{\\c&H00FFFFFF}${w.word.toUpperCase()}`; // White for the other words
                  }
              }).join(' ');

              // Add the dialogue for each word transition
              wordTimings.push(`Dialogue: 0,${wordStartTime},${wordEndTime},Default,,0,0,0,,${coloredWords}`);




















              const WHITE_COLOR = "\\1c&HFFFFFF&";
const GREEN_COLOR = "\\1c&H00FF00&";


function createAssFile(transcriptionData: any, subtitleStyle: any) {
  const transcription = JSON.parse(transcriptionData);
  let assContent = `
[Script Info]
Title: Subtitles
ScriptType: v4.00+

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial,40,&H00FFFFFF,&H00000000,&H00000000,&H00000000,1,1,0,2,10,10,30,0

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
`;

  let previousEndTime = 0; // Store the end time of the previous dialogue

  // Iterate through each transcription segment
  transcription.segments.forEach((segment: any) => {
    const words = segment.words;

    
    const timings = words.map((word: any) => Math.round(word.start * 1000)); // Convert start times to ms
    timings.push(Math.round(words[words.length - 1].end * 1000)); // Append the final end time

    // Convert the word list to the same format as in highlight_words_by_timing
    const sentence = words.map((word: any) => word.word).join(' ');

    // Apply the highlight_words_by_timing logic to get the formatted ASS dialogue
    const highlightedDialogue = highlight_words_by_timing(timings, sentence);

    // Calculate the start and end time of the segment
    const segmentStartTime = words[0].start;
    const segmentEndTime = words[words.length - 1].end;

    // Format the time for ASS file
    const segmentStartTimeFormatted = formatTime(segmentStartTime);
    const segmentEndTimeFormatted = formatTime(segmentEndTime);

    // Create the dialogue line for ASS file
    const dialogue = `Dialogue: 0,${segmentStartTimeFormatted},${segmentEndTimeFormatted},Default,,0,0,0,,${highlightedDialogue}\n`;

    assContent += dialogue;

    // Update previousEndTime
    previousEndTime = segmentEndTime;
  });

  return assContent;
}
// This function remains the same as in your highlight_words_by_timing implementation
function highlight_words_by_timing(timings: number[], sentence: string): string {
  if (timings.length !== sentence.split(' ').length + 1) {
    throw new Error("Number of timings does not match the number of words plus one.");
  }

  const words = sentence.split(' ');

  let command = "";

  words.forEach((word, i) => {
    const tag = `{${WHITE_COLOR}\\t(${timings[i]},${timings[i]},${GREEN_COLOR})\\t(${timings[i + 1]},${timings[i + 1]},${WHITE_COLOR})}${word} `;
    command += tag;
  });

  return command.trim();
}

// Utility function to format time for ASS file
function formatTime(seconds: number) {
  if (isNaN(seconds) || seconds === undefined || seconds === null) {
    return "00:00:00.00"; // Default to 0 if the time is invalid
  }
  const hours = Math.floor(seconds / 3600).toString().padStart(2, '0');
  const minutes = Math.floor((seconds % 3600) / 60).toString().padStart(2, '0');
  const secs = (seconds % 60).toFixed(2).padStart(5, '0');
  return `${hours}:${minutes}:${secs}`;
}
highlight  word end ==============================>

   =================================>>>

function createAssFile(transcriptionData: any, subtitleStyle: any) {
  const transcription = JSON.parse(transcriptionData);
  let assContent = `
[Script Info]
Title: Subtitles
ScriptType: v4.00+

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial,40,&H00FFFFFF,&H00000000,&H00000000,&H00000000,1,1,0,2,10,10,30,0

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
`;

let lastWordEndTime = 0; // Variable to store the last word's end time across segments

const modifiedSegments = transcription.segments.map((segment: any) => {
  const modifiedWords = segment.words.map((word: any, index: number) => {
      // Handle missing start time
      if (!word.start) {
          if (index > 0 && segment.words[index - 1].end) {
              word.start = segment.words[index - 1].end; // Use previous word's end time as start time
          } else if (index === 0 && lastWordEndTime) {
              word.start = lastWordEndTime; // Use last word's end time from the previous segment
          }
      }

      // Handle missing end time
      if (!word.end && index < segment.words.length - 1) {
          word.end = segment.words[index + 1].start; // Use next word's start time as end time
      }

      // Update the lastWordEndTime for the next segment
      lastWordEndTime = word.end || lastWordEndTime;

      return {
          word: word.word,
          start: word.start,
          end: word.end,
          score: word.score,
          speaker: word.speaker,
      };
  });

  return {
      start: segment.start,
      end: segment.end,
      text: segment.text,
      words: modifiedWords,
      speaker: segment.speaker,
  };
});


// Return or log the modified transcription structure


  // Iterate through each transcription segment
  modifiedSegments.forEach((segment: any,segIndex: number) => {
    let words:any[] = [];
    let borrowWordCount = 0 ;
     words = segment.words;
     if (borrowWordCount > 0) {
      // Remove borrowWordCount items from the words array
      words.splice(0, borrowWordCount);
      borrowWordCount= 0 ;
  }
    
    
    for (let i = 0; i < words.length; i += 3) {
      let wordGroup = words.slice(i, i + 3);

      if(wordGroup.length < 3 && segIndex < modifiedSegments.length - 1 ){
        const nextSegment = modifiedSegments[segIndex + 1];
        const nextWords = nextSegment.words.slice(0, 3 - wordGroup.length);
        borrowWordCount = nextWords.length
        
        wordGroup = [...wordGroup, ...nextWords];
      }

      // Get the start time of the first word in the group
      const threeWordGroupStartTime = wordGroup[0].start  // Fallback to previous end time
      const threeWordGroupEndTime = wordGroup[wordGroup.length - 1].end;
// ------------------------------->
const WHITE_COLOR = "\\1c&HFFFFFF&";
const GREEN_COLOR = "\\1c&H00FF00&";

const modifiedWords = words.map((word: any, index: number) => {
  // Handle missing start time
  if (!word.start) {
    if (index > 0 && words[index - 1].end) {
      word.start = words[index - 1].end; // Use previous word's end time as start time
    }
  }

  // Handle missing end time
  if (!word.end && index < words.length - 1) {
    word.end = words[index + 1].start  // Set to next word's start or add default duration
  }

  return word;
});

      const timings = modifiedWords.map((word: any) => Math.round(word.start * 1000)); // Convert start times to ms
      timings.push(Math.round(words[words.length - 1].end * 1000)); // Append the final end time
      let command = "";
// ------------------------------->


const updatedWordGroup =  wordGroup.map((word: any, index: number) => {
  if (!word.start || !word.end) {
    // Use previous word's end time as the current word's start time if missing
    if (index > 0 && !word.start) {
      word.start = wordGroup[index - 1].end || threeWordGroupStartTime;
    }
    // Use the next word's start time as the current word's end time if missing
    if (index < wordGroup.length - 1 && !word.end) {
      word.end = wordGroup[index + 1].start || threeWordGroupEndTime;
    }
  }
  return word;

})



      // Handle missing start and end times
      updatedWordGroup.forEach((word: any, index: number) => {
        
// ------------------------------->

        const tag = `{${WHITE_COLOR}\\t(${timings[index]},${timings[index]},${GREEN_COLOR})\\t(${timings[index + 1]},${timings[index + 1]},${WHITE_COLOR})}${word.word} `;
    command += tag;
    
// ------------------------------->

      });

// ------------------------------->


      command = command.trim();
// ------------------------------->


      
      const threeWordGroupStartTimeFormatted = formatTime(threeWordGroupStartTime); 
      const threeWordGroupEndTimeFormatted = formatTime(threeWordGroupEndTime);

      
      const dialogue = `Dialogue: 0,${threeWordGroupStartTimeFormatted},${threeWordGroupEndTimeFormatted},Default,,0,0,0,,${command}\n`;
      // const text = wordGroup.map((word: any) => word.word).join(' ');
      assContent += dialogue;

      // Update the previousEndTime to the current group's end time for the next group
    }
  });

  return assContent;
}



----->current word 

[Script Info]
Title: Example Subtitles
ScriptType: v4.00+

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial,40,&H00FFFFFF,&H00000000,&H00000000,&H00000000,1,1,0,2,10,10,30,0

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
Dialogue: 0,0:00:00.00,0:00:00.67,Default,,0,0,0,,{\1c&HFFFFFF&\t(0,335,\1c&H00FF00&)\t(670,670,\1c&HFFFFFF&)}1%
Dialogue: 0,0:00:00.67,0:00:01.29,Default,,0,0,0,,{\1c&HFFFFFF&\t(0, 100,\1c&H00FF00&)\t(100,100,\1c&HFFFFFF&)}of {\1c&HFFFFFF&\t(100,100,\1c&H00FF00&)\t(300,300,\1c&HFFFFFF&)}people
Dialogue: 0,0:00:01.33,0:00:04.95,Default,,0,0,0,,{\1c&HFFFFFF&\t(0,60,\1c&H00FF00&)\t(60,60,\1c&HFFFFFF&)}in {\1c&HFFFFFF&\t(60,60,\1c&H00FF00&)\t(120,120,\1c&HFFFFFF&)}this {\1c&HFFFFFF&\t(120,120,\1c&H00FF00&)\t(361,361,\1c&HFFFFFF&)}country.
-->basically transition works  relative to its dialogue time   if there are three words   "hi how are"   every word have   start and end time  e.g hi start time  is  1  and time is 2  similarly for all  combine dialogue time is 1-3  now for each word the transition duation will be  according  to start and end time  of word  

{\1c&HFFFFFF&\t(0,60,\1c&H00FF00&)\t(60,60,\1c&HFFFFFF&)}in {\1c&HFFFFFF&\t(60,60,\1c&H00FF00&)\t(120,120,\1c&HFFFFFF&)}this
\t(60,60,\1c&HFFFFFF&)     "in"  start and end time duration  (change second to ms) 
\t(120,120,\1c&HFFFFFF&)  "this"




[Script Info]
Title: Example Subtitles
ScriptType: v4.00+

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial,40,&H00FFFFFF,&H00000000,&H00000000,&H00000000,1,1,0,2,10,10,30,0

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text

Dialogue: 0,0:00:00.00,0:00:00.67,Default,,0,0,0,,{\1c&HFFFFFF&\t(0,335,\1c&H00FF00&)\t(670,670,\1c&HFFFFFF&)}1%
Dialogue: 0,0:00:00.67,0:00:01.29,Default,,0,0,0,,{\1c&HFFFFFF&\t(0, 100,\1c&H00FF00&)\t(100,100,\1c&HFFFFFF&)}of {\1c&HFFFFFF&\t(100,100,\1c&H00FF00&)\t(300,300,\1c&HFFFFFF&)}people
Dialogue: 0,0:00:01.33,0:00:04.95,Default,,0,0,0,,{\1c&HFFFFFF&\t(0,60,\1c&H00FF00&)\t(60,60,\1c&HFFFFFF&)}in {\1c&HFFFFFF&\t(60,60,\1c&H00FF00&)\t(120,120,\1c&HFFFFFF&)}this {\1c&HFFFFFF&\t(120,120,\1c&H00FF00&)\t(361,361,\1c&HFFFFFF&)}country.
Dialogue: 0,0:00:51.52,0:00:53.55,Default,,0,0,0,,{\1c&HFFFFFF&\t(0,5,\1c&H00FF00&)\t(1162,1162,\1c&HFFFFFF&)}craziest {\1c&HFFFFFF&\t(1162,5,\1c&H00FF00&)\t(1442,1442,\1c&HFFFFFF&)}Gini {\1c&HFFFFFF&\t(1442,5,\1c&H00FF00&)}coefficients,



cat ~/.ssh/id_rsa.pub





absl-py==2.1.0
aiohappyeyeballs==2.4.3
aiohttp==3.10.10
aiosignal==1.3.1
alembic==1.13.3
antlr4-python3-runtime==4.9.3
asteroid-filterbanks==0.4.0
async-timeout==4.0.3
attrs==24.2.0
audioread==3.0.1
av==11.0.0
certifi==2024.8.30
cffi==1.17.1
charset-normalizer==3.4.0
click==8.1.7
clipsai==0.2.1
colorama==0.4.6
coloredlogs==15.0.1
colorlog==6.8.2
contourpy==1.3.0
ctranslate2==4.4.0
cycler==0.12.1
decorator==4.4.2
diffusers==0.30.3
docopt==0.6.2
einops==0.8.0
exceptiongroup==1.2.2
facenet-pytorch==2.6.0
faster-whisper==1.0.1
ffmpeg-python==0.2.0
filelock==3.16.1
flatbuffers==24.3.25
fonttools==4.54.1
frozenlist==1.4.1
fsspec==2024.9.0
future==1.0.0
greenlet==3.1.1
huggingface-hub==0.25.2
humanfriendly==10.0
HyperPyYAML==1.2.2
idna==3.10
imageio==2.36.0
imageio-ffmpeg==0.5.1
importlib_metadata==8.5.0
iniconfig==2.0.0
jax==0.4.34
jaxlib==0.4.34
Jinja2==3.1.4
joblib==1.4.2
julius==0.2.7
kiwisolver==1.4.7
lazy_loader==0.4
librosa==0.10.2.post1
lightning==2.4.0
lightning-utilities==0.11.7
llvmlite==0.43.0
Mako==1.3.5
markdown-it-py==3.0.0
MarkupSafe==3.0.1
matplotlib==3.9.2
mdurl==0.1.2
mediapipe==0.10.14
ml_dtypes==0.5.0
moviepy==1.0.3
mpmath==1.3.0
msgpack==1.1.0
multidict==6.1.0
networkx==3.4.1
nltk==3.9.1
numba==0.60.0
numpy==1.26.4
omegaconf==2.3.0
onnxruntime==1.19.2
opencv-contrib-python==4.10.0.84
opencv-python==4.10.0.84
opt_einsum==3.4.0
optuna==4.0.0
packaging==24.1
pandas==2.2.3
pillow==10.2.0
platformdirs==4.3.6
pluggy==1.5.0
pooch==1.8.2
primePy==1.3
proglog==0.1.10
propcache==0.2.0
protobuf==4.25.5
psutil==6.0.0
pyannote.audio==3.1.1
pyannote.core==5.0.0
pyannote.database==5.1.0
pyannote.metrics==3.2.1
pyannote.pipeline==3.0.1
pycparser==2.22
Pygments==2.18.0
pynvml==11.5.3
pyparsing==3.2.0
pyreadline3==3.5.4
pytest==8.3.3
python-dateutil==2.9.0.post0
python-magic==0.4.27
python-magic-bin==0.4.14
pytorch-lightning==2.4.0
pytorch-metric-learning==2.6.0
pytz==2024.2
PyYAML==6.0.2
regex==2024.9.11
requests==2.32.3
rich==13.9.2
ruamel.yaml==0.18.6
ruamel.yaml.clib==0.2.8
safetensors==0.4.5
scenedetect==0.6.4
scikit-learn==1.5.2
scipy==1.14.1
semver==3.0.2
sentence-transformers==3.1.1
sentencepiece==0.2.0
shellingham==1.5.4
six==1.16.0
sortedcontainers==2.4.0
sounddevice==0.5.1
soundfile==0.12.1
soxr==0.5.0.post1
speechbrain==1.0.1
SQLAlchemy==2.0.35
sympy==1.13.3
tabulate==0.9.0
tensorboardX==2.6.2.2
threadpoolctl==3.5.0
tokenizers==0.15.2
tomli==2.0.2
torch==2.2.2
torch-audiomentations==0.11.1
torch_pitch_shift==1.2.5
torchaudio==2.2.2
torchmetrics==1.4.3
torchvision==0.17.2
tqdm==4.66.5
transformers==4.39.3
typer==0.12.5
typing_extensions==4.12.2
tzdata==2024.2
urllib3==2.2.3
whisperx==3.1.5
yarl==1.15.2
zipp==3.20.2




docker file : 
# Use an official Node.js image as the base image
FROM node:20.8.0

# Install dependencies for building Python from source and Rust
RUN apt-get update && apt-get install -y  \
    wget \
    curl \
    build-essential \
    zlib1g-dev \
    libffi-dev \
    libssl-dev \
    libbz2-dev \
    libreadline-dev \
    libsqlite3-dev \
    libncurses5-dev \
    libncursesw5-dev \
    xz-utils \
    tk-dev \
    liblzma-dev \
    git \
    ffmpeg \
    imagemagick \
    libhdf5-dev \
    libmagic1 \
    python3-venv \
    python3 \
    && rm -rf /var/lib/apt/lists/*  # Clean up to reduce image size

# Install Python 3.10
RUN wget https://www.python.org/ftp/python/3.10.0/Python-3.10.0.tgz \
    && tar xzf Python-3.10.0.tgz \
    && cd Python-3.10.0 \
    && ./configure --enable-optimizations \
    && make altinstall \
    && cd .. \
    && rm -rf Python-3.10.0.tgz Python-3.10.0

# Install Rust using rustup
RUN curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
ENV PATH="/root/.cargo/bin:${PATH}"

# Set the working directory inside the container
WORKDIR /app

# Create and activate a Python virtual environment using Python 3.10
RUN python3.10 -m venv /myenv
ENV PATH="/myenv/bin:$PATH"

# Install setuptools-rust in the virtual environment
RUN pip install --upgrade pip setuptools-rust

# Install Python dependencies
COPY requirements.txt .
RUN pip install -r requirements.txt \
    && pip install nltk \
    && python3.10 -m nltk.downloader -d /usr/local/share/nltk_data punkt punkt_tab vader_lexicon

# RUN pip install torch==2.0.0 torchvision==0.15.0 torchaudio==2.0.0 --index-url https://download.pytorch.org/whl/cpu

# Copy package.json and package-lock.json first to leverage Docker cache
COPY package.json package-lock.json ./

# Increase NPM timeout and retry installation on failure
RUN npm config set fetch-retries 5 \
    && npm config set fetch-retry-mintimeout 20000 \
    && npm config set fetch-retry-maxtimeout 120000 \
    && npm install || npm install || npm install  # Retry on failure

# Copy the remaining app files
COPY . .

# Make environment variables dynamic (loaded at runtime)
ARG NEXTAUTH_URL
ARG NEXTAUTH_SECRET
ARG SMTP_HOST
ARG SMTP_PORT
ARG SMTP_USER
ARG SMTP_PASSWORD
ARG SMTP_FROM
ARG DATABASE_URL
ARG APP_URL
ARG SVIX_URL
ARG SVIX_API_KEY
ARG GITHUB_CLIENT_ID
ARG GITHUB_CLIENT_SECRET
ARG GOOGLE_CLIENT_ID
ARG GOOGLE_CLIENT_SECRET
ARG STRIPE_SECRET_KEY
ARG STRIPE_WEBHOOK_SECRET
ARG NEXT_PUBLIC_DARK_MODE
ARG PORT

# Set environment variables dynamically using ARG for better flexibility
ENV NEXTAUTH_URL=$NEXTAUTH_URL
ENV NEXTAUTH_SECRET=$NEXTAUTH_SECRET
ENV SMTP_HOST=$SMTP_HOST
ENV SMTP_PORT=$SMTP_PORT
ENV SMTP_USER=$SMTP_USER
ENV SMTP_PASSWORD=$SMTP_PASSWORD
ENV SMTP_FROM=$SMTP_FROM
ENV DATABASE_URL=$DATABASE_URL
ENV APP_URL=$APP_URL
ENV SVIX_URL=$SVIX_URL
ENV SVIX_API_KEY=$SVIX_API_KEY
ENV GITHUB_CLIENT_ID=$GITHUB_CLIENT_ID
ENV GITHUB_CLIENT_SECRET=$GITHUB_CLIENT_SECRET
ENV GOOGLE_CLIENT_ID=$GOOGLE_CLIENT_ID
ENV GOOGLE_CLIENT_SECRET=$GOOGLE_CLIENT_SECRET
ENV STRIPE_SECRET_KEY=$STRIPE_SECRET_KEY
ENV STRIPE_WEBHOOK_SECRET=$STRIPE_WEBHOOK_SECRET
ENV NEXT_PUBLIC_DARK_MODE=$NEXT_PUBLIC_DARK_MODE
ENV PORT=$PORT
# Optional: Add any other dynamic variables
ENV NODE_ENV=production

# Expose the port for the application
EXPOSE 4002

# Add logging to check the db:setup command
RUN echo "Running db:setup..."
RUN npx prisma generate
RUN npm run build
# RUN npm run db:setup

# Start the Next.js app in development mode
CMD ["npm", "run", "start"]
